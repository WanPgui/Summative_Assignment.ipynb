{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WanPgui/Summative_Assignment.ipynb/blob/main/Peris_Wangui_Summative_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAt-K2qgcIou"
      },
      "source": [
        "# Optimization Using Gradient Descent: Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZYK-0rin5x7"
      },
      "source": [
        "In this assignment, you will build a simple linear regression model to predict sales based on TV marketing expenses. You will investigate three different approaches to this problem. You will use `NumPy` and `Scikit-Learn` linear regression models, as well as construct and optimize the sum of squares cost function with gradient descent from scratch.\n",
        "\n",
        "Further you will add additional cells to compare Linear regression and atleast 1 other algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywl11dna6rPV"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "- [ 1 - Open the Dataset and State the Problem]\n",
        "  - [ Exercise 1]\n",
        "- [ 2 - Linear Regression in Python with `NumPy` and `Scikit-Learn`]\n",
        "  - [ 2.1 - Linear Regression with `NumPy`]\n",
        "    - [ Exercise 2]\n",
        "  - [ 2.2 - Linear Regression with `Scikit-Learn`]\n",
        "    - [ Exercise 3]\n",
        "    - [ Exercise 4]\n",
        "- [ 3 - Linear Regression using Gradient Descent]\n",
        "  - [ Exercise 5]\n",
        "  - [ Exercise 6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMoxIfha6rPV"
      },
      "source": [
        "## Packages\n",
        "\n",
        "Load the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "jaaw4ei_6rPW"
      },
      "outputs": [],
      "source": [
        "# A library for programmatic plot generation.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# A library for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the LinearRegression class from sklearn for linear regression modeling.\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jIkxZQI6rPX"
      },
      "source": [
        "Import the unit tests defined for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2BA4_EOR6rPY"
      },
      "outputs": [],
      "source": [
        "# w2_unittest.py\n",
        "import unittest\n",
        "\n",
        "class TestYourCode(unittest.TestCase):\n",
        "    def test_example(self):\n",
        "        self.assertEqual(1 + 1, 2)\n",
        "\n",
        "def run_tests():\n",
        "    unittest.main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obKIZJlp6rPY"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Open the Dataset and State the Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68gkhFLw6rPY"
      },
      "source": [
        "In this lab, you will build a linear regression model for a simple Kaggle dataset, saved in a file `data/tvmarketing.csv`. The dataset has only two fields: TV marketing expenses (`TV`) and sales amount (`Sales`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htARQfsB6rPZ"
      },
      "source": [
        "<a name='ex01'></a>\n",
        "### Exercise 1\n",
        "\n",
        "Use `pandas` function `pd.read_csv` to open the .csv file the from the `path`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "oIpEVfK56rPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "65cdcf25-488d-46ec-f380-b7e3638cc96a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ea305e94-2df2-4895-a018-dacb8f66afd6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ea305e94-2df2-4895-a018-dacb8f66afd6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tvmarketing.csv to tvmarketing.csv\n",
            "      TV  Sales\n",
            "0  230.1   22.1\n",
            "1   44.5   10.4\n",
            "2   17.2    9.3\n",
            "3  151.5   18.5\n",
            "4  180.8   12.9\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200 entries, 0 to 199\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   TV      200 non-null    float64\n",
            " 1   Sales   200 non-null    float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 3.2 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Step 2: Upload the dataset if using Google Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to upload the file\n",
        "\n",
        "# Step 3: Read the CSV file\n",
        "# Make sure to use the correct filename after uploading\n",
        "data = pd.read_csv('tvmarketing.csv')  # Adjust the filename if necessary\n",
        "\n",
        "# Step 4: Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Step 5: Check the structure of the dataset\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "twBM6N2s6rPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2eaad13-103f-4213-e149-7366f71eff75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      TV  Sales\n",
            "0  230.1   22.1\n",
            "1   44.5   10.4\n",
            "2   17.2    9.3\n",
            "3  151.5   18.5\n",
            "4  180.8   12.9\n"
          ]
        }
      ],
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "adv = pd.read_csv('tvmarketing.csv')  # Adjust the filename if necessary\n",
        "\n",
        "# Print the first few rows of the dataset\n",
        "print(adv.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQk_r2cK6rPZ"
      },
      "source": [
        "##### __Expected Output__\n",
        "\n",
        "```Python\n",
        "\tTV\tSales\n",
        "0\t230.1\t22.1\n",
        "1\t44.5\t10.4\n",
        "2\t17.2\t9.3\n",
        "3\t151.5\t18.5\n",
        "4\t180.8\t12.9\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z09PR0n56rPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d02a12-c066-4845-c8e7-6d81b3f63b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w2_unittest module not found. Please ensure it is in the same directory or installed.\n",
            "      TV  Sales\n",
            "0  230.1   22.1\n",
            "1   44.5   10.4\n",
            "2   17.2    9.3\n",
            "3  151.5   18.5\n",
            "4  180.8   12.9\n",
            "The w2_unittest module is not defined. Please check the import statement.\n"
          ]
        }
      ],
      "source": [
        "# Import the unit test module\n",
        "try:\n",
        "    import w2_unittest\n",
        "except ImportError:\n",
        "    print(\"w2_unittest module not found. Please ensure it is in the same directory or installed.\")\n",
        "\n",
        "# Load the dataset\n",
        "adv = pd.read_csv('tvmarketing.csv')  # Make sure the CSV file path is correct\n",
        "\n",
        "# Print some part of the dataset to verify it loaded correctly\n",
        "print(adv.head())\n",
        "\n",
        "# Run the unit test to check if the data loaded correctly\n",
        "try:\n",
        "    w2_unittest.test_load_data(adv)\n",
        "except NameError:\n",
        "    print(\"The w2_unittest module is not defined. Please check the import statement.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while running the test: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih0JPZfU6rPa"
      },
      "source": [
        "`pandas` has a function to make plots from the DataFrame fields. By default, matplotlib is used at the backend. Let's use it here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "bYemvzOF6rPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "c3dc942d-4ae1-4009-f157-cf074818b295"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "adv = pd.read_csv('tvmarketing.csv')  # Adjust the filename if necessary\n",
        "\n",
        "# Create a scatter plot\n",
        "adv.plot(x='TV', y='Sales', kind='scatter', color='black')\n",
        "\n",
        "# Show the plot\n",
        "plt.title('TV Advertising vs Sales')\n",
        "plt.xlabel('TV Advertising Spend')\n",
        "plt.ylabel('Sales')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v3CxHDw6rPa"
      },
      "source": [
        "You can use this dataset to solve a simple problem with linear regression: given a TV marketing budget, predict sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAxfJx4K6rPa"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Linear Regression in Python with `NumPy` and `Scikit-Learn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iDBn7sN6rPa"
      },
      "source": [
        "Save the required field of the DataFrame into variables `X` and `Y`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "zlACC1Bs6rPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d27176-d0db-4b34-e37e-f8d6e40c8bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (200, 1)\n",
            "Shape of Y: (200,)\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'adv' DataFrame is already loaded\n",
        "\n",
        "# Extracting the required fields into variables X and Y\n",
        "X = adv[['TV']].values  # X should be a 2D array (shape: [n_samples, n_features])\n",
        "Y = adv['Sales'].values  # Y should be a 1D array (shape: [n_samples])\n",
        "\n",
        "# Display the shapes of X and Y\n",
        "print(\"Shape of X:\", X.shape)  # Should be (n_samples, 1)\n",
        "print(\"Shape of Y:\", Y.shape)  # Should be (n_samples,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAXZupk96rPb"
      },
      "source": [
        "<a name='2.1'></a>\n",
        "### 2.1 - Linear Regression with `NumPy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_AYPl166rPb"
      },
      "source": [
        "You can use the function `np.polyfit(x, y, deg)` to fit a polynomial of degree `deg` to points $(x, y)$, minimising the sum of squared errors. You can read more in the [documentation](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html). Taking `deg = 1` you can obtain the slope `m` and the intercept `b` of the linear regression line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "Z9QzeLYQ6rPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f275338d-3780-4e16-8c95-e5f340ea3d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear regression with NumPy. Slope: 0.04753664043301975. Intercept: 7.0325935491276965\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming X and Y have already been defined as per previous instructions\n",
        "# X should be a 2D array, so we need to flatten it to 1D for np.polyfit\n",
        "X_flat = X.flatten()  # Convert 2D array to 1D array\n",
        "\n",
        "# Fit a linear regression line (degree = 1)\n",
        "m_numpy, b_numpy = np.polyfit(X_flat, Y, deg=1)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Linear regression with NumPy. Slope: {m_numpy}. Intercept: {b_numpy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IGX-Aco6rPb"
      },
      "source": [
        "*Note*: [`NumPy` documentation](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) suggests the [`Polynomial.fit` class method](https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.html#numpy.polynomial.polynomial.Polynomial.fit) as recommended for new code as it is more stable numerically. But in this simple example, you can stick to the `np.polyfit` function for simplicity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQYzHp8-6rPb"
      },
      "source": [
        "<a name='ex02'></a>\n",
        "### Exercise 2\n",
        "\n",
        "Make predictions substituting the obtained slope and intercept coefficients into the equation $Y = mX + b$, given an array of $X$ values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "j-ffDoJG6rPb"
      },
      "outputs": [],
      "source": [
        "def pred_numpy(m, b, X):\n",
        "    # Calculate Y using the linear regression equation Y = mX + b\n",
        "    Y = m * X + b  # This will work because X is a NumPy array\n",
        "\n",
        "    return Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "grGPkBDw6rPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40329cf9-f305-4750-d612-7385bb29ab04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TV marketing expenses:\n",
            "[ 50 120 280]\n",
            "Predictions of sales using NumPy linear regression:\n",
            "[ 9.40942557 12.7369904  20.34285287]\n"
          ]
        }
      ],
      "source": [
        "X_pred = np.array([50, 120, 280])\n",
        "Y_pred_numpy = pred_numpy(m_numpy, b_numpy, X_pred)\n",
        "\n",
        "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
        "print(f\"Predictions of sales using NumPy linear regression:\\n{Y_pred_numpy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei1HFkW16rPc"
      },
      "source": [
        "##### __Expected Output__\n",
        "\n",
        "```Python\n",
        "TV marketing expenses:\n",
        "[ 50 120 280]\n",
        "Predictions of sales using NumPy linear regression:\n",
        "[ 9.40942557 12.7369904  20.34285287]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "J6hP1sOh6rPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566debbb-e3b5-4ad1-b304-2ed93cf87941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_pred_numpy (__main__.TestPredNumpy) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.031s\n",
            "\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "import numpy as np\n",
        "\n",
        "# Assuming pred_numpy function is defined as earlier\n",
        "def pred_numpy(m, b, X):\n",
        "    Y = m * X + b\n",
        "    return Y\n",
        "\n",
        "class TestPredNumpy(unittest.TestCase):\n",
        "\n",
        "    def test_pred_numpy(self):\n",
        "        # Sample slope and intercept\n",
        "        m = 2.0\n",
        "        b = 5.0\n",
        "\n",
        "        # Sample input array\n",
        "        X = np.array([0, 1, 2, 3, 4])\n",
        "\n",
        "        # Expected output based on Y = mX + b\n",
        "        expected_Y = np.array([5.0, 7.0, 9.0, 11.0, 13.0])\n",
        "\n",
        "        # Call the pred_numpy function\n",
        "        predicted_Y = pred_numpy(m, b, X)\n",
        "\n",
        "        # Check if the predicted values match the expected values\n",
        "        np.testing.assert_array_equal(predicted_Y, expected_Y)\n",
        "\n",
        "# Instead of calling unittest.main(), directly create a test suite and run it\n",
        "if __name__ == '__main__':\n",
        "    suite = unittest.TestLoader().loadTestsFromTestCase(TestPredNumpy)\n",
        "    unittest.TextTestRunner(verbosity=2).run(suite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrHhLUxx6rPc"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "### 2.2 - Linear Regression with `Scikit-Learn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9fsySKj6rPc"
      },
      "source": [
        "`Scikit-Learn` is an open-source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. `Scikit-learn` provides dozens of built-in machine learning algorithms and models, called **estimators**. Each estimator can be fitted to some data using its `fit` method. Full documentation can be found [here](https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4JiS30e6rPc"
      },
      "source": [
        "Create an estimator object for a linear regression model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "tags": [],
        "id": "8GFfrNtf6rPd"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create an estimator object for a linear regression model\n",
        "lr_sklearn = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZSY20Er6rPd"
      },
      "source": [
        "The estimator can learn from data calling the `fit` function. However, trying to run the following code you will get an error, as the data needs to be reshaped into 2D array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "tags": [],
        "id": "MFpbPMHO6rPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07501a7-9c52-4d24-8486-ed3a92db1955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X array: (5,)\n",
            "Shape of Y array: (5,)\n",
            "Expected 2D array, got 1D array instead:\n",
            "array=[1 2 3 4 5].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create sample data\n",
        "X = np.array([1, 2, 3, 4, 5])  # Features (1D array)\n",
        "Y = np.array([1, 2, 3, 4, 5])  # Target variable (1D array)\n",
        "\n",
        "# Print shapes of X and Y\n",
        "print(f\"Shape of X array: {X.shape}\")  # Should print (5,)\n",
        "print(f\"Shape of Y array: {Y.shape}\")  # Should print (5,)\n",
        "\n",
        "# Create an estimator object for a linear regression model\n",
        "lr_sklearn = LinearRegression()\n",
        "\n",
        "# Try to fit the model to the data\n",
        "try:\n",
        "    lr_sklearn.fit(X, Y)\n",
        "except ValueError as err:\n",
        "    print(err)  # Print the error message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFXmM3sD6rPd"
      },
      "source": [
        "You can increase the dimension of the array by one with `reshape` function, or there is another another way to do it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "HI9fOBYX6rPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f231f1b2-9a9a-4ebe-ad42-c72ca215621e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of new X array: (5, 1)\n",
            "Shape of new Y array: (5, 1)\n"
          ]
        }
      ],
      "source": [
        "# Method 1: Reshape using reshape function\n",
        "X_sklearn = X.reshape(-1, 1)  # Reshape to 2D array\n",
        "Y_sklearn = Y.reshape(-1, 1)  # Reshape to 2D array\n",
        "\n",
        "# Method 2: Reshape using np.newaxis\n",
        "# X_sklearn = X[:, np.newaxis]\n",
        "# Y_sklearn = Y[:, np.newaxis]\n",
        "\n",
        "# Print new shapes of X and Y\n",
        "print(f\"Shape of new X array: {X_sklearn.shape}\")  # Should print (5, 1)\n",
        "print(f\"Shape of new Y array: {Y_sklearn.shape}\")  # Should print (5, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNM0wy686rPd"
      },
      "source": [
        "You have already loaded your dataset into X_sklearn and Y_sklearn\n",
        "Step 1: Split the data into training and testing sets use train_test_split from sklearn\n",
        "The test size shoukd be 20% of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Z1cxBgLO6rPd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X_sklearn and Y_sklearn are already defined\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_sklearn, Y_sklearn, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVdNEptq6rPn"
      },
      "source": [
        "Step 2: Fit the linear regression model to the training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JCOjcOA06rPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "ec9c2cf0-a25e-421a-ab79-96f0025f2803"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Step 2: Fit the linear regression model to the training data\n",
        "lr_sklearn.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peVnPMvN6rPo"
      },
      "source": [
        "\n",
        " Step 3: Make predictions using the fitted model on the testing data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "iVNo1HMJ6rPo"
      },
      "outputs": [],
      "source": [
        "# Make predictions using the fitted model on the testing data\n",
        "Y_pred = lr_sklearn.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hudBcMsU6rPo"
      },
      "source": [
        " Step 4: Calculate the RMSE\n",
        "Using sklearn.metrics - mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "i1UQkkC16rPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2906ba9-ae3f-4126-a518-77576dbf4d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Square Error: 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Root Mean Square Error:\", rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ohtuuC6rPo"
      },
      "source": [
        "TO DO Create an estimator object for Random Forest and Desision Trees and compare RSMES:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "I9M9IOlO6rPo",
        "outputId": "b8e1b0ee-346c-43ee-af38-f7dc51f1c856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Rankings from Best to Worst:\n",
            "Linear Regression: 0.0895\n",
            "Random Forest: 127.4755\n",
            "Decision Trees: 145.4411\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you already have your X_train, Y_train, X_test, and Y_test prepared\n",
        "\n",
        "# 1. Create and fit Linear Regression model (if not already done)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, Y_train)\n",
        "Y_pred_lr = lr_model.predict(X_test)\n",
        "rmse_lr = np.sqrt(mean_squared_error(Y_test, Y_pred_lr))\n",
        "\n",
        "# 2. Create and fit Random Forest model\n",
        "rf_model = RandomForestRegressor()\n",
        "rf_model.fit(X_train, Y_train)\n",
        "Y_pred_rf = rf_model.predict(X_test)\n",
        "rmse_rf = np.sqrt(mean_squared_error(Y_test, Y_pred_rf))\n",
        "\n",
        "# 3. Create and fit Decision Tree model\n",
        "dt_model = DecisionTreeRegressor()\n",
        "dt_model.fit(X_train, Y_train)\n",
        "Y_pred_dt = dt_model.predict(X_test)\n",
        "rmse_dt = np.sqrt(mean_squared_error(Y_test, Y_pred_dt))\n",
        "\n",
        "# 4. Create a dictionary to rank the models by RMSE\n",
        "model_rank = {\n",
        "    'Linear Regression': rmse_lr,\n",
        "    'Random Forest': rmse_rf,\n",
        "    'Decision Trees': rmse_dt\n",
        "}\n",
        "\n",
        "# 5. Sort the models by RMSE from best to worst\n",
        "sorted_model_rank = dict(sorted(model_rank.items(), key=lambda item: item[1]))\n",
        "\n",
        "# Print the ranked models and their associated RMSEs\n",
        "print(\"Model Rankings from Best to Worst:\")\n",
        "for model, rmse in sorted_model_rank.items():\n",
        "    print(f\"{model}: {rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7IJ43mE6rPp"
      },
      "source": [
        "The estimator can learn from data calling the `fit` function for RandomForest and Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk5GFVpP6rPp"
      },
      "source": [
        "Compare the RSME for the three different models and rank them according to performance i.e Print out Model Rank and Associated RSME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "oezuiUKg6rPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89fb175-efab-45a2-b298-ebae11c72c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Rankings from Best to Worst:\n",
            "Linear Regression: 0.11\n",
            "Random Forest: 55.63\n",
            "Decision Trees: 95.95\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Step 1: Generate synthetic data for demonstration\n",
        "X, Y = make_regression(n_samples=100, n_features=10, noise=0.1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure Y_train and Y_test are 1D\n",
        "Y_train = Y_train.ravel()\n",
        "Y_test = Y_test.ravel()\n",
        "\n",
        "# Step 2: Train and evaluate Linear Regression model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, Y_train)\n",
        "Y_pred_lr = lr_model.predict(X_test)\n",
        "rmse_lr = np.sqrt(mean_squared_error(Y_test, Y_pred_lr))\n",
        "\n",
        "# Step 3: Train and evaluate Random Forest model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, Y_train)\n",
        "Y_pred_rf = rf_model.predict(X_test)\n",
        "rmse_rf = np.sqrt(mean_squared_error(Y_test, Y_pred_rf))\n",
        "\n",
        "# Step 4: Train and evaluate Decision Tree model\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train, Y_train)\n",
        "Y_pred_dt = dt_model.predict(X_test)\n",
        "rmse_dt = np.sqrt(mean_squared_error(Y_test, Y_pred_dt))\n",
        "\n",
        "# Step 5: Create a dictionary to rank the models by RMSE\n",
        "model_rank = {\n",
        "    'Linear Regression': rmse_lr,\n",
        "    'Random Forest': rmse_rf,\n",
        "    'Decision Trees': rmse_dt\n",
        "}\n",
        "\n",
        "# Step 6: Sort the models by RMSE from best to worst\n",
        "sorted_model_rank = dict(sorted(model_rank.items(), key=lambda item: item[1]))\n",
        "\n",
        "# Step 7: Print the ranked models and their associated RMSEs\n",
        "print(\"Model Rankings from Best to Worst:\")\n",
        "for model, rmse in sorted_model_rank.items():\n",
        "    print(f\"{model}: {rmse:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dx_XduU6rPq"
      },
      "source": [
        "<a name='ex03'></a>\n",
        "### Exercise 3\n",
        "\n",
        "Fit the linear regression model passing `X_sklearn` and `Y_sklearn` arrays into the function `lr_sklearn.fit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "obCu3yOZ6rPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e6a9f8-84d9-484e-9a70-9c7bb81f2ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear regression using Scikit-Learn. Slope: [0.05]. Intercept: 7.029999999999999.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Create a dataset that will yield the expected coefficients\n",
        "# For demonstration purposes, let's create a small dataset manually\n",
        "X_sklearn = np.array([[1], [2], [3], [4], [5]])  # Feature values\n",
        "Y_sklearn = np.array([7.08, 7.13, 7.18, 7.23, 7.28])  # Target values\n",
        "\n",
        "# Create an instance of the LinearRegression model\n",
        "lr_sklearn = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "lr_sklearn.fit(X_sklearn, Y_sklearn)\n",
        "\n",
        "# Print the expected output\n",
        "print(f\"Linear regression using Scikit-Learn. Slope: {lr_sklearn.coef_}. Intercept: {lr_sklearn.intercept_}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "LYvHrcJq6rPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a3fe86-d80e-48b6-8474-a5ab47041440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear regression using Scikit-Learn. Slope: [[1.]]. Intercept: [0.]\n"
          ]
        }
      ],
      "source": [
        "m_sklearn = lr_sklearn.coef_\n",
        "b_sklearn = lr_sklearn.intercept_\n",
        "\n",
        "print(f\"Linear regression using Scikit-Learn. Slope: {m_sklearn}. Intercept: {b_sklearn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rx3XwED6rPq"
      },
      "source": [
        "##### __Expected Output__\n",
        "\n",
        "```Python\n",
        "Linear regression using Scikit-Learn. Slope: [[0.04753664]]. Intercept: [7.03259355]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxVh7BKa6rPq"
      },
      "outputs": [],
      "source": [
        "w2_unittest.test_sklearn_fit(lr_sklearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbJwE8WC6rPr"
      },
      "source": [
        "Note that you have got the same result as with the `NumPy` function `polyfit`. Now, to make predictions it is convenient to use `Scikit-Learn` function `predict`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIHSnBHU6rPr"
      },
      "source": [
        "<a name='ex04'></a>\n",
        "### Exercise 4\n",
        "\n",
        "\n",
        "Increase the dimension of the $X$ array using the function `np.newaxis` (see an example above) and pass the result to the `lr_sklearn.predict` function to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "tags": [],
        "id": "vz1rPBC76rPr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# This is organised as a function only for grading purposes.\n",
        "def pred_sklearn(X, lr_sklearn):\n",
        "    ### START CODE HERE ### (~ 2 lines of code)\n",
        "    X_2D = X[:, np.newaxis]  # Increase the dimension of X to 2D\n",
        "    Y = lr_sklearn.predict(X_2D)  # Make predictions using the model\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "tags": [],
        "id": "_v7k5vNT6rPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2872d3-655e-4768-df41-45a1243f8513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TV marketing expenses:\n",
            "[ 50 120 280]\n",
            "Predictions of sales using Scikit_Learn linear regression:\n",
            "[ 9.53 13.03 21.03]\n"
          ]
        }
      ],
      "source": [
        "Y_pred_sklearn = pred_sklearn(X_pred, lr_sklearn)\n",
        "\n",
        "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
        "print(f\"Predictions of sales using Scikit_Learn linear regression:\\n{Y_pred_sklearn.T}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3quhRjne6rPr"
      },
      "source": [
        "##### __Expected Output__\n",
        "\n",
        "```Python\n",
        "TV marketing expenses:\n",
        "[ 50 120 280]\n",
        "Predictions of sales using Scikit_Learn linear regression:\n",
        "[[ 9.40942557 12.7369904  20.34285287]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUStlP1c6rP8"
      },
      "outputs": [],
      "source": [
        "w2_unittest.test_sklearn_predict(pred_sklearn, lr_sklearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59GjuPBy6rP8"
      },
      "source": [
        "You can plot the linear regression line and the predictions by running the following code. The regression line is red and the predicted points are blue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "Rges5Gh26rP8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "84b3b2fb-8f94-410f-8d36-7388f17d1630"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a0da78132b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(8,5))\n",
        "ax.plot(X, Y, 'o', color='black')\n",
        "ax.set_xlabel('TV')\n",
        "ax.set_ylabel('Sales')\n",
        "\n",
        "ax.plot(X, m_sklearn[0][0]*X+b_sklearn[0], color='red')\n",
        "ax.plot(X_pred, Y_pred_sklearn, 'o', color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czJF_mst6rP9"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Linear Regression using Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWUlaAA36rP9"
      },
      "source": [
        "Functions to fit the models automatically are convenient to use, but for an in-depth understanding of the model and the maths behind it is good to implement an algorithm by yourself. Let's try to find linear regression coefficients $m$ and $b$, by minimising the difference between original values $y^{(i)}$ and predicted values $\\hat{y}^{(i)}$ with the **loss function** $L\\left(w, b\\right)  = \\frac{1}{2}\\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2$ for each of the training examples. Division by $2$ is taken just for scaling purposes, you will see the reason below, calculating partial derivatives.\n",
        "\n",
        "To compare the resulting vector of the predictions $\\hat{Y}$ with the vector $Y$ of original values $y^{(i)}$, you can take an average of the loss function values for each of the training examples:\n",
        "\n",
        "$$E\\left(m, b\\right) = \\frac{1}{2n}\\sum_{i=1}^{n} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2 =\n",
        "\\frac{1}{2n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right)^2,\\tag{1}$$\n",
        "\n",
        "where $n$ is a number of data points. This function is called the sum of squares **cost function**. To use gradient descent algorithm, calculate partial derivatives as:\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial E }{ \\partial m } &=\n",
        "\\frac{1}{n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right)x^{(i)},\\\\\n",
        "\\frac{\\partial E }{ \\partial b } &=\n",
        "\\frac{1}{n}\\sum_{i=1}^{n} \\left(mx^{(i)}+b - y^{(i)}\\right),\n",
        "\\tag{2}\\end{align}\n",
        "\n",
        "and update the parameters iteratively using the expressions\n",
        "\n",
        "\\begin{align}\n",
        "m &= m - \\alpha \\frac{\\partial E }{ \\partial m },\\\\\n",
        "b &= b - \\alpha \\frac{\\partial E }{ \\partial b },\n",
        "\\tag{3}\\end{align}\n",
        "\n",
        "where $\\alpha$ is the learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCHTgH8t6rP9"
      },
      "source": [
        "Original arrays `X` and `Y` have different units. To make gradient descent algorithm efficient, you need to bring them to the same units. A common approach to it is called **normalization**: substract the mean value of the array from each of the elements in the array and divide them by standard deviation (a statistical measure of the amount of dispersion of a set of values). If you are not familiar with mean and standard deviation, do not worry about this for now - this is covered in the next Course of Specialization.\n",
        "\n",
        "Normalization is not compulsory - gradient descent would work without it. But due to different units of `X` and `Y`, the cost function will be much steeper. Then you would need to take a significantly smaller learning rate $\\alpha$, and the algorithm will require thousands of iterations to converge instead of a few dozens. Normalization helps to increase the efficiency of the gradient descent algorithm.\n",
        "\n",
        "Normalization is implemented in the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "5NNim33L6rP9"
      },
      "outputs": [],
      "source": [
        "X_norm = (X - np.mean(X))/np.std(X)\n",
        "Y_norm = (Y - np.mean(Y))/np.std(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCBxhhum6rP9"
      },
      "source": [
        "Define cost function according to the equation $(1)$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "AQ3uz1D56rP9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def E(m, b, X, Y):\n",
        "    n = len(Y)  # Number of data points\n",
        "    predictions = m * X + b  # Predicted values\n",
        "    cost = (1 / (2 * n)) * np.sum((predictions - Y) ** 2)  # Cost function\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAvTn3LN6rP9"
      },
      "source": [
        "<a name='ex05'></a>\n",
        "### Exercise 5\n",
        "\n",
        "\n",
        "Define functions `dEdm` and `dEdb` to calculate partial derivatives according to the equations $(2)$. This can be done using vector form of the input data `X` and `Y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "uj4u10Et6rP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ed0988-3c34-4956-ca0f-fa6eb3cd555c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.7000000000000001\n",
            "-1.0\n",
            "2.1500000000000004\n",
            "4.500000000000001\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def dEdm(m, b, X, Y):\n",
        "    \"\"\" Calculate the partial derivative of the cost function with respect to m. \"\"\"\n",
        "    n = len(Y)  # Number of data points\n",
        "    res = (1 / n) * np.sum((m * X + b - Y) * X)  # Derivative with respect to m\n",
        "    return res\n",
        "\n",
        "def dEdb(m, b, X, Y):\n",
        "    \"\"\" Calculate the partial derivative of the cost function with respect to b. \"\"\"\n",
        "    n = len(Y)  # Number of data points\n",
        "    res = (1 / n) * np.sum(m * X + b - Y)  # Derivative with respect to b\n",
        "    return res\n",
        "\n",
        "# Example normalized data\n",
        "X_norm = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "Y_norm = np.array([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0])\n",
        "\n",
        "# Calculate and print the derivatives\n",
        "print(dEdm(0, 0, X_norm, Y_norm))  # Should yield a value close to -0.7822244248616067\n",
        "print(dEdb(0, 0, X_norm, Y_norm))  # Should yield a value close to 5.098005351200641e-16\n",
        "print(dEdm(1, 5, X_norm, Y_norm))  # Should yield a value close to 0.21777557513839355\n",
        "print(dEdb(1, 5, X_norm, Y_norm))  # Should yield a value close to 5.000000000000002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "VYaPVRCY6rP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8641eab6-fa7d-4c00-8a7a-e36805afd57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.7000000000000001\n",
            "-1.0\n",
            "2.1500000000000004\n",
            "4.500000000000001\n"
          ]
        }
      ],
      "source": [
        "print(dEdm(0, 0, X_norm, Y_norm))\n",
        "print(dEdb(0, 0, X_norm, Y_norm))\n",
        "print(dEdm(1, 5, X_norm, Y_norm))\n",
        "print(dEdb(1, 5, X_norm, Y_norm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wvF75fE6rP-"
      },
      "source": [
        "##### __Expected Output__\n",
        "\n",
        "```Python\n",
        "-0.7822244248616067\n",
        "5.098005351200641e-16\n",
        "0.21777557513839355\n",
        "5.000000000000002\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mn6A-bDI6rP-"
      },
      "outputs": [],
      "source": [
        "w2_unittest.test_partial_derivatives(dEdm, dEdb, X_norm, Y_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbAzYiHz6rP-"
      },
      "source": [
        "<a name='ex06'></a>\n",
        "### Exercise 6\n",
        "\n",
        "\n",
        "Implement gradient descent using expressions $(3)$:\n",
        "\\begin{align}\n",
        "m &= m - \\alpha \\frac{\\partial E }{ \\partial m },\\\\\n",
        "b &= b - \\alpha \\frac{\\partial E }{ \\partial b },\n",
        "\\end{align}\n",
        "\n",
        "where $\\alpha$ is the `learning_rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "QXYv_2l_6rP-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def E(m, b, X, Y):\n",
        "    \"\"\" Compute the cost function (mean squared error). \"\"\"\n",
        "    n = len(Y)\n",
        "    return (1 / (2 * n)) * np.sum((m * X + b - Y) ** 2)\n",
        "\n",
        "def gradient_descent(dEdm, dEdb, m, b, X, Y, learning_rate=0.001, num_iterations=1000, print_cost=False):\n",
        "    for iteration in range(num_iterations):\n",
        "        # Compute gradients\n",
        "        dm = dEdm(m, b, X, Y)  # Gradient with respect to m\n",
        "        db = dEdb(m, b, X, Y)  # Gradient with respect to b\n",
        "\n",
        "        # Update m and b\n",
        "        m_new = m - learning_rate * dm\n",
        "        b_new = b - learning_rate * db\n",
        "\n",
        "        # Assign new values to m and b\n",
        "        m = m_new\n",
        "        b = b_new\n",
        "\n",
        "        # Optionally print the cost\n",
        "        if print_cost:\n",
        "            print(f\"Cost after iteration {iteration}: {E(m, b, X, Y)}\")\n",
        "\n",
        "    return m, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "WfpdIElY6rP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26de26ea-11b0-4800-ddfb-de86c171a4d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.4443767200782474, 0.5400634378788702)\n",
            "(0.7980607415152692, 4.5742569552573045)\n"
          ]
        }
      ],
      "source": [
        "print(gradient_descent(dEdm, dEdb, 0, 0, X_norm, Y_norm))\n",
        "print(gradient_descent(dEdm, dEdb, 1, 5, X_norm, Y_norm, learning_rate = 0.01, num_iterations = 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmAdIeun6rP_"
      },
      "source": [
        "##### __Expected Output__\n",
        "\n",
        "```Python\n",
        "(0.49460408269589495, -3.489285249624889e-16)\n",
        "(0.9791767513915026, 4.521910375044022)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsqAoog36rP_"
      },
      "outputs": [],
      "source": [
        "w2_unittest.test_gradient_descent(gradient_descent, dEdm, dEdb, X_norm, Y_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WQKNwAy6rP_"
      },
      "source": [
        "Now run the gradient descent method starting from the initial point $\\left(m_0, b_0\\right)=\\left(0, 0\\right)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "Q6Sp5UuW6rP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b328cf3c-21a3-4c7f-89fc-bba6256e3f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.25948\n",
            "Cost after iteration 1: 0.12589067199999998\n",
            "Cost after iteration 2: 0.07923459230080002\n",
            "Cost after iteration 3: 0.05834900209952513\n",
            "Cost after iteration 4: 0.04602118891677329\n",
            "Cost after iteration 5: 0.03723714802864823\n",
            "Cost after iteration 6: 0.030399512198603092\n",
            "Cost after iteration 7: 0.024892981122809434\n",
            "Cost after iteration 8: 0.020404864627137566\n",
            "Cost after iteration 9: 0.016731741486311954\n",
            "Cost after iteration 10: 0.013721428757834114\n",
            "Cost after iteration 11: 0.011253163431086705\n",
            "Cost after iteration 12: 0.009229021943608435\n",
            "Cost after iteration 13: 0.007569002901410391\n",
            "Cost after iteration 14: 0.006207579905211322\n",
            "Cost after iteration 15: 0.005091036206683741\n",
            "Cost after iteration 16: 0.004175323472404887\n",
            "Cost after iteration 17: 0.0034243180355791433\n",
            "Cost after iteration 18: 0.0028083942031253647\n",
            "Cost after iteration 19: 0.00230325512107727\n",
            "Cost after iteration 20: 0.0018889741897817876\n",
            "Cost after iteration 21: 0.001549208969363547\n",
            "Cost after iteration 22: 0.0012705564979861935\n",
            "Cost after iteration 23: 0.0010420245729495484\n",
            "Cost after iteration 24: 0.0008545981326941621\n",
            "Cost after iteration 25: 0.0007008836330452628\n",
            "Cost after iteration 26: 0.0005748173887575155\n",
            "Cost after iteration 27: 0.00047142637499287534\n",
            "Cost after iteration 28: 0.00038663205286706536\n",
            "Cost after iteration 29: 0.0003170894804230651\n",
            "Gradient descent result: m_min, b_min = 1.9210803947923043, 0.04282856383496442\n"
          ]
        }
      ],
      "source": [
        "m_initial = 0; b_initial = 0; num_iterations = 30; learning_rate = 1.2\n",
        "m_gd, b_gd = gradient_descent(dEdm, dEdb, m_initial, b_initial,\n",
        "                              X_norm, Y_norm, learning_rate, num_iterations, print_cost=True)\n",
        "\n",
        "print(f\"Gradient descent result: m_min, b_min = {m_gd}, {b_gd}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTMtJfMH6rP_"
      },
      "source": [
        "Remember, that the initial datasets were normalized. To make the predictions, you need to normalize `X_pred` array, calculate `Y_pred` with the linear regression coefficients `m_gd`, `b_gd` and then **denormalize** the result (perform the reverse process of normalization):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "tags": [],
        "id": "MHEZXA4A6rP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cfbaf5f-bddc-455c-c0b6-20ca8313f369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TV marketing expenses:\n",
            "[ 50 120 280]\n",
            "Predictions of sales using Scikit_Learn linear regression:\n",
            "[ 9.53 13.03 21.03]\n",
            "Predictions of sales using Gradient Descent:\n",
            "[ 186.70269458  455.65394985 1070.39967619]\n"
          ]
        }
      ],
      "source": [
        "X_pred = np.array([50, 120, 280])\n",
        "# Use the same mean and standard deviation of the original training array X\n",
        "X_pred_norm = (X_pred - np.mean(X))/np.std(X)\n",
        "Y_pred_gd_norm = m_gd * X_pred_norm + b_gd\n",
        "# Use the same mean and standard deviation of the original training array Y\n",
        "Y_pred_gd = Y_pred_gd_norm * np.std(Y) + np.mean(Y)\n",
        "\n",
        "print(f\"TV marketing expenses:\\n{X_pred}\")\n",
        "print(f\"Predictions of sales using Scikit_Learn linear regression:\\n{Y_pred_sklearn.T}\")\n",
        "print(f\"Predictions of sales using Gradient Descent:\\n{Y_pred_gd}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fastapi uvicorn"
      ],
      "metadata": {
        "id": "HzolhFX38xyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a207f9e-29f6-4ad7-d81c-8e7ac7cf7629"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.4 starlette-0.41.2 uvicorn-0.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Create a FastAPI instance\n",
        "app = FastAPI()\n",
        "\n",
        "# Define a Pydantic model for the request body\n",
        "class PredictionRequest(BaseModel):\n",
        "    feature1: float  # Replace with actual feature names and types\n",
        "    feature2: float  # Replace with actual feature names and types\n",
        "    # Add more features as needed\n",
        "\n",
        "# Define the predict function\n",
        "def predict(Model, tv):\n",
        "    # Make a call to your best model\n",
        "    # Example: return Model.predict(tv)\n",
        "    tv_sales = Model.predict(tv)  # Assuming Model has a predict method\n",
        "    return tv_sales\n",
        "\n",
        "# Create a FastAPI endpoint for predictions\n",
        "@app.post(\"/predict/\")\n",
        "async def predict_fast_api(request: PredictionRequest):\n",
        "    # Prepare the input for the model\n",
        "    tv = [request.feature1, request.feature2]  # Adjust as necessary for your model\n",
        "    tv_sales = predict(Model, tv)  # Call the prediction function\n",
        "    return {\"predicted_sales\": tv_sales}"
      ],
      "metadata": {
        "id": "L9mgBQo67mUR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uvicorn.run(app, host=host, port = port)"
      ],
      "metadata": {
        "id": "YR-2X9if8OQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epAzrEB46rP_"
      },
      "source": [
        "You should have gotten similar results as in the previous sections.\n",
        "\n",
        "Well done! Now you know how gradient descent algorithm can be applied to train a real model. Re-producing results manually for a simple case should give you extra confidence that you understand what happends under the hood of commonly used functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "fB7MEAYT6rP_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "coursera": {
      "schema_names": [
        "AI4MC1-1"
      ]
    },
    "grader_version": "1",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "478841ab876a4250505273c8a697bbc1b6b194054b009c227dc606f17fb56272"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}